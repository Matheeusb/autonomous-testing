# ğŸ“˜ PolÃ­tica de GeraÃ§Ã£o de Testes de Performance com k6

## ğŸ¯ Objetivo

Este documento define as regras obrigatÃ³rias para que o GitHub Copilot (ou agentes de IA) gerem testes de performance utilizando **k6**, garantindo:

- PadronizaÃ§Ã£o
- Realismo de cenÃ¡rios
- Confiabilidade de mÃ©tricas
- CritÃ©rios objetivos de falha
- Compatibilidade com execuÃ§Ã£o local e CI (GitHub Actions)
- Alinhamento com regras de negÃ³cio documentadas

---

# ğŸ§  Papel do Agente

Ao gerar testes de performance, o agente deve:

1. Analisar:
   - DocumentaÃ§Ã£o de regras de negÃ³cio
   - Contratos formais dos endpoints
   - Fluxos funcionais crÃ­ticos
   - Requisitos nÃ£o funcionais (SLA, throughput, latÃªncia)

2. Identificar:
   - Endpoints crÃ­ticos
   - OperaÃ§Ãµes mais utilizadas
   - OperaÃ§Ãµes sensÃ­veis (login, criaÃ§Ã£o, atualizaÃ§Ã£o, exclusÃ£o)

3. Gerar:
   - CenÃ¡rios realistas
   - Thresholds coerentes
   - Scripts organizados e reutilizÃ¡veis
   - Testes independentes e reproduzÃ­veis

---

# ğŸ“¥ Entradas ObrigatÃ³rias

O agente deve utilizar como fonte de verdade:

- DocumentaÃ§Ã£o formal das regras de negÃ³cio
- Contratos definidos fora do Swagger
- Requisitos de SLA definidos no projeto
- ConfiguraÃ§Ã£o de ambientes (dev, staging, test)

Nunca inferir comportamento apenas pelo Swagger.

---

# ğŸ“ Estrutura ObrigatÃ³ria de DiretÃ³rios

performance/
â”‚
â”œâ”€â”€ config/
â”‚ â””â”€â”€ environments.js
â”‚
â”œâ”€â”€ helpers/
â”‚ â””â”€â”€ auth.js
â”‚
â”œâ”€â”€ scenarios/
â”‚ â”œâ”€â”€ smoke.js
â”‚ â”œâ”€â”€ load.js
â”‚ â”œâ”€â”€ stress.js
â”‚ â””â”€â”€ spike.js
â”‚
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ <feature>.load.test.js
â”‚
â””â”€â”€ k6.config.js

---

# âš™ï¸ Estrutura ObrigatÃ³ria do Script

Todo teste gerado deve conter:

- export const options
- CenÃ¡rios explÃ­citos
- Thresholds obrigatÃ³rios
- Uso de variÃ¡veis de ambiente
- SimulaÃ§Ã£o de think time
- Checks funcionais mÃ­nimos

---

# ğŸ“Š Thresholds ObrigatÃ³rios

Os seguintes thresholds devem sempre existir:

http_req_duration: ['p(95)<SLA_MS']
http_req_failed: ['rate<0.01']
checks: ['rate>0.99']


Se o projeto definir SLAs especÃ­ficos, o agente deve utilizÃ¡-los.

---

# ğŸ“ˆ Tipos de CenÃ¡rios que Devem Ser Criados

## 1. Smoke Performance
- 1 a 5 usuÃ¡rios
- ExecuÃ§Ã£o curta
- Valida disponibilidade

## 2. Load Test
- Simula carga esperada de produÃ§Ã£o
- Ramp-up gradual
- SustentaÃ§Ã£o mÃ­nima de 3 minutos

## 3. Stress Test
- Ultrapassa carga nominal
- Identifica ponto de degradaÃ§Ã£o

## 4. Spike Test
- Crescimento abrupto de usuÃ¡rios
- Mede elasticidade

---

# ğŸ” AutenticaÃ§Ã£o

Se a API utiliza Bearer Token:

- O token deve ser obtido dinamicamente
- Nunca hardcode tokens
- Utilizar variÃ¡vel de ambiente
- Modularizar autenticaÃ§Ã£o em helper separado

---

# â±ï¸ SimulaÃ§Ã£o de Comportamento Real

O agente deve:

- Utilizar sleep()
- Variar think time
- Agrupar fluxos com group()
- Simular sequÃªncia real de uso da API

Exemplo:

- Login
- Criar recurso
- Buscar recurso
- Atualizar recurso
- Deletar recurso

---

# ğŸ§ª Regras de Qualidade

O agente deve garantir:

- Scripts legÃ­veis
- ModularizaÃ§Ã£o
- Nenhuma duplicaÃ§Ã£o desnecessÃ¡ria
- SeparaÃ§Ã£o de dados de teste
- NÃ£o uso de console.log excessivo
- CÃ³digo compatÃ­vel com execuÃ§Ã£o em CI

---

# ğŸš€ ExecuÃ§Ã£o Local

Os testes devem poder ser executados via:

k6 run performance/tests/<arquivo>.js


Com suporte a:

-e BASE_URL
-e ENVIRONMENT
-e TOKEN

---

# ğŸ”„ ExecuÃ§Ã£o na Pipeline (GitHub Actions)

Os testes devem:

- Exportar relatÃ³rio JSON
- Falhar automaticamente se thresholds forem violados
- NÃ£o depender de interaÃ§Ã£o manual
- Ser executÃ¡veis via comando CLI simples

Exemplo esperado:

k6 run performance/tests/load.test.js --summary-export=summary.json

A pipeline deve falhar se:

- SLA for ultrapassado
- Taxa de erro > 1%
- Checks < 99%

---

# âŒ Anti-PadrÃµes Proibidos

O agente nÃ£o deve:

- Testar produÃ§Ã£o sem autorizaÃ§Ã£o explÃ­cita
- Hardcode URLs
- Hardcode tokens
- Criar testes sem thresholds
- Criar testes apenas com GET simples sem simular fluxo real
- Ignorar regras de negÃ³cio

---

# ğŸ“‰ CritÃ©rios de Aceite

Um teste de carga sÃ³ Ã© considerado vÃ¡lido se:

- Simular cenÃ¡rio real
- Conter thresholds definidos
- Executar localmente
- Executar em CI
- Falhar automaticamente quando necessÃ¡rio
- Utilizar autenticaÃ§Ã£o corretamente
- Estiver alinhado Ã s regras de negÃ³cio

---

# ğŸ“Œ DefiniÃ§Ã£o de Pronto (Definition of Done)

- [ ] CenÃ¡rio baseado em fluxo real
- [ ] Thresholds definidos
- [ ] VariÃ¡veis de ambiente utilizadas
- [ ] AutenticaÃ§Ã£o modularizada
- [ ] Script organizado
- [ ] ExecuÃ§Ã£o validada localmente
- [ ] CompatÃ­vel com GitHub Actions
- [ ] RelatÃ³rio exportÃ¡vel

---

# ğŸ§­ Filosofia

Testes de performance nÃ£o devem medir apenas requisiÃ§Ãµes por segundo.

Devem validar:

- Estabilidade
- ResiliÃªncia
- Comportamento sob pressÃ£o
- Conformidade com SLA
- ExperiÃªncia do usuÃ¡rio sob volume

Performance Ã© requisito nÃ£o funcional crÃ­tico e deve ser tratada como parte do contrato do sistema.
