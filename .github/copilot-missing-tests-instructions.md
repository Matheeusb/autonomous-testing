# InstruÃ§Ãµes para CriaÃ§Ã£o de Testes UnitÃ¡rios Ausentes â€“ GitHub Copilot

## ğŸ¯ Objetivo

Quando novas funcionalidades forem adicionadas ao cÃ³digo-fonte sem testes unitÃ¡rios correspondentes, o GitHub Copilot deve analisar o cÃ³digo alterado e criar os testes unitÃ¡rios necessÃ¡rios, abrindo um Pull Request com os novos testes.

---

## ğŸ” Processo de AnÃ¡lise

### 1. Identificar os arquivos sem cobertura de testes

- Leia a lista de arquivos alterados que nÃ£o possuem teste correspondente
- Leia a lista de arquivos com cobertura abaixo do threshold
- Analise o cÃ³digo-fonte de cada arquivo identificado

### 2. Analisar o cÃ³digo-fonte

Para cada arquivo sem teste:

- Identifique todas as funÃ§Ãµes e mÃ©todos exportados
- Mapeie as regras de negÃ³cio implementadas
- Identifique pontos de decisÃ£o (if/else, switch, try/catch)
- Liste as dependÃªncias externas que precisam ser mockadas

### 3. Consultar a documentaÃ§Ã£o de referÃªncia

Antes de criar os testes, consulte obrigatoriamente:

- `/docs/business-rules.md` â€“ Regras de negÃ³cio
- `/docs/domain-model.md` â€“ Modelo de domÃ­nio
- `/docs/api-contracts/*` â€“ Contratos da API
- `/quality-rules/unit-test.instructions.md` â€“ PadrÃµes de qualidade dos testes

---

## ğŸ› ï¸ Regras para CriaÃ§Ã£o de Testes

### Estrutura dos testes

Os testes devem seguir a estrutura existente no projeto:

| Arquivo fonte | Arquivo de teste esperado |
|---------------|--------------------------|
| `src/services/novoService.js` | `tests/unit/services/novoService.test.js` |
| `src/controllers/novoController.js` | `tests/unit/controllers/novoController.test.js` |
| `src/middlewares/novoMiddleware.js` | `tests/unit/middlewares/novoMiddleware.test.js` |

### Cobertura obrigatÃ³ria

Cada arquivo de teste deve cobrir:

- **Happy path** â€“ CenÃ¡rios de sucesso para cada funÃ§Ã£o
- **CenÃ¡rios negativos** â€“ Entradas invÃ¡lidas, erros esperados
- **Valores limite** â€“ Edge cases relevantes
- **Tratamento de erros** â€“ ExceÃ§Ãµes e fluxos de erro
- **CenÃ¡rios de seguranÃ§a** â€“ ValidaÃ§Ã£o de permissÃµes quando aplicÃ¡vel

### PadrÃµes obrigatÃ³rios

- Usar **Jest** como framework de testes
- Seguir o padrÃ£o **AAA** (Arrange, Act, Assert)
- Nomenclatura: `should <comportamento esperado> when <condiÃ§Ã£o>`
- Mockar dependÃªncias externas (repositÃ³rios, serviÃ§os)
- NÃ£o acessar banco de dados real ou serviÃ§os externos

### Metas de cobertura

- **Statements:** â‰¥ 90%
- **Branches:** â‰¥ 85%
- **Functions:** â‰¥ 90%

---

## ğŸ“ Formato do Pull Request

O PR criado pelo Copilot deve conter:

### TÃ­tulo
```
test: adiciona testes unitÃ¡rios para [nome do mÃ³dulo/funcionalidade]
```

### DescriÃ§Ã£o

```markdown
## Contexto
[DescriÃ§Ã£o de quais arquivos foram adicionados/modificados sem cobertura de testes]

## Testes Criados
- [ ] `tests/unit/path/arquivo.test.js` â€“ [descriÃ§Ã£o dos cenÃ¡rios cobertos]

## Cobertura
- CenÃ¡rios de sucesso: X testes
- CenÃ¡rios de erro: X testes
- Valores limite: X testes

## ReferÃªncia
- Issue: #<numero>
- Regras de negÃ³cio: [regras especÃ­ficas cobertas]
```

### Labels
- `copilot-fix`
- `missing-tests`
- `automated`

---

## âš ï¸ SituaÃ§Ãµes Especiais

### Quando NÃƒO criar testes automaticamente

O Copilot **nÃ£o deve** criar testes e deve apenas comentar na Issue quando:

- O arquivo Ã© apenas de configuraÃ§Ã£o (`src/config/*`)
- O cÃ³digo Ã© gerado automaticamente
- A funcionalidade requer integraÃ§Ãµes externas complexas para testar
- HÃ¡ ambiguidade nas regras de negÃ³cio que impede a criaÃ§Ã£o de assertions claras

Nesses casos, adicione um comentÃ¡rio na Issue com:
```
âš ï¸ Testes para [arquivo] requerem anÃ¡lise manual. Motivo: [explicaÃ§Ã£o]
```

### Arquivos com cobertura baixa (mas teste existente)

- Analise o teste existente para identificar cenÃ¡rios faltantes
- Adicione os cenÃ¡rios ausentes ao arquivo de teste existente
- NÃ£o crie um novo arquivo de teste separado

---

## ğŸ”„ ValidaÃ§Ã£o

Antes de abrir o PR, o Copilot deve:

1. Verificar que todos os novos testes passam
2. Verificar que os testes existentes continuam passando
3. Garantir que os testes seguem os padrÃµes de `/quality-rules/unit-test.instructions.md`
4. Confirmar que a cobertura dos arquivos afetados atingiu o threshold mÃ­nimo
